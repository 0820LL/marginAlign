Logging set at level: INFO
Logging to file: None
Using the following working directory: tests
Using the following output directory: tests/output
Got the following read fasta files: tests/readFastaFiles/reads.fa
Got the following reference fasta files: tests/referenceFastaFiles/reference.fa
Logging set at level: INFO
Logging to file: None
Starting to create the job tree setup for the first time
Setting up the thread pool with 4 threads given the max threads 4 and the max cpus 9223372036854775807
Using the single machine batch system
Written the config file
Finished the job tree setup
Adding the first job
Added the first job
Written the environment for the jobs to the environment file
Got parameters,rescue jobs frequency: 5400.0 max job duration: 9.22337203685e+18
Checked batch system has no running jobs and no updated jobs
Found 1 jobs to start and 0 parent jobs with children to run
Starting the main loop
Got message from job at time: 1403585980.0 : Root output dir already exists: tests/output
The job seems to have left a log file, indicating failure: /cluster/home/ifiddes/try2/nanopore/testJobTree/jobs/t0/job
Reporting file: /cluster/home/ifiddes/try2/nanopore/testJobTree/jobs/t0/log.txt
log.txt:	---JOBTREE SLAVE OUTPUT LOG---
log.txt:	Parsed arguments and set up logging
log.txt:	Starting the next job
log.txt:	Starting the next job
log.txt:	Traceback (most recent call last):
log.txt:	  File "/cluster/home/ifiddes/try2/nanopore/submodules/jobTree/src/jobTreeSlave.py", line 271, in main
log.txt:	    defaultMemory=defaultMemory, defaultCpu=defaultCpu, depth=depth)
log.txt:	  File "/cluster/home/ifiddes/try2/nanopore/submodules/jobTree/scriptTree/stack.py", line 153, in execute
log.txt:	    self.target.run()
log.txt:	  File "/cluster/home/ifiddes/try2/nanopore/submodules/jobTree/scriptTree/target.py", line 197, in run
log.txt:	    func(*((self,) + tuple(self.args)), **self.kwargs)
log.txt:	  File "/cluster/home/ifiddes/try2/nanopore/nanopore/pipeline.py", line 50, in runAnalyses
log.txt:	    target.addChildTarget(analysis(readFastaFile, referenceFastaFile, samFile, analysisDir))
log.txt:	TypeError: __init__() takes exactly 1 argument (5 given)
log.txt:	Exiting the slave because of a failed job on host kolossus
log.txt:	Due to failure we are reducing the remaining retry count of job /cluster/home/ifiddes/try2/nanopore/testJobTree/jobs/t0/job to 0
log.txt:	We have set the default memory of the failed job to 2147483648 bytes
log.txt:	Experiment dir tests/output/experiment_reads.fa_reference.fa_Lastz
Got message from job at time: 1403585980.73 : Experiment dir already exists: tests/output/experiment_reads.fa_reference.fa_Lastz
Job: /cluster/home/ifiddes/try2/nanopore/testJobTree/jobs/t0/job is completely failed
The job seems to have left a log file, indicating failure: /cluster/home/ifiddes/try2/nanopore/testJobTree/jobs/t2/job
Reporting file: /cluster/home/ifiddes/try2/nanopore/testJobTree/jobs/t2/log.txt
log.txt:	---JOBTREE SLAVE OUTPUT LOG---
log.txt:	Parsed arguments and set up logging
log.txt:	Starting the next job
log.txt:	Starting the next job
log.txt:	Traceback (most recent call last):
log.txt:	  File "/cluster/home/ifiddes/try2/nanopore/submodules/jobTree/src/jobTreeSlave.py", line 271, in main
log.txt:	    defaultMemory=defaultMemory, defaultCpu=defaultCpu, depth=depth)
log.txt:	  File "/cluster/home/ifiddes/try2/nanopore/submodules/jobTree/scriptTree/stack.py", line 153, in execute
log.txt:	    self.target.run()
log.txt:	  File "/cluster/home/ifiddes/try2/nanopore/submodules/jobTree/scriptTree/target.py", line 197, in run
log.txt:	    func(*((self,) + tuple(self.args)), **self.kwargs)
log.txt:	  File "/cluster/home/ifiddes/try2/nanopore/nanopore/pipeline.py", line 50, in runAnalyses
log.txt:	    target.addChildTarget(analysis(readFastaFile, referenceFastaFile, samFile, analysisDir))
log.txt:	TypeError: __init__() takes exactly 1 argument (5 given)
log.txt:	Exiting the slave because of a failed job on host kolossus
log.txt:	Due to failure we are reducing the remaining retry count of job /cluster/home/ifiddes/try2/nanopore/testJobTree/jobs/t2/job to 0
log.txt:	We have set the default memory of the failed job to 2147483648 bytes
log.txt:	Experiment dir tests/output/experiment_reads.fa_reference.fa_Last
Got message from job at time: 1403585980.75 : Experiment dir already exists: tests/output/experiment_reads.fa_reference.fa_Last
Job: /cluster/home/ifiddes/try2/nanopore/testJobTree/jobs/t2/job is completely failed
The job seems to have left a log file, indicating failure: /cluster/home/ifiddes/try2/nanopore/testJobTree/jobs/t1/job
Reporting file: /cluster/home/ifiddes/try2/nanopore/testJobTree/jobs/t1/log.txt
log.txt:	---JOBTREE SLAVE OUTPUT LOG---
log.txt:	Parsed arguments and set up logging
log.txt:	Starting the next job
log.txt:	[bwa_index] Pack FASTA... 0.00 sec
log.txt:	[bwa_index] Construct BWT for the packed sequence...
log.txt:	[bwa_index] 0.01 seconds elapse.
log.txt:	[bwa_index] Update BWT... 0.00 sec
log.txt:	[bwa_index] Pack forward-only FASTA... 0.00 sec
log.txt:	[bwa_index] Construct SA from BWT and Occ... 0.01 sec
log.txt:	[main] Version: 0.7.9a-r786
log.txt:	[main] CMD: bwa index /scratch/tmp/tmp5o_V2b/localTempDir/ref.fa
log.txt:	[main] Real time: 0.291 sec; CPU: 0.029 sec
log.txt:	[M::main_mem] read 2 sequences (71186 bp)...
log.txt:	[M::mem_process_seqs] Processed 2 reads in 0.594 CPU sec, 0.596 real sec
log.txt:	[main] Version: 0.7.9a-r786
log.txt:	[main] CMD: bwa mem -x pacbio /scratch/tmp/tmp5o_V2b/localTempDir/ref.fa tests/readFastaFiles/reads.fa
log.txt:	[main] Real time: 0.599 sec; CPU: 0.597 sec
log.txt:	Starting the next job
log.txt:	Traceback (most recent call last):
log.txt:	  File "/cluster/home/ifiddes/try2/nanopore/submodules/jobTree/src/jobTreeSlave.py", line 271, in main
log.txt:	    defaultMemory=defaultMemory, defaultCpu=defaultCpu, depth=depth)
log.txt:	  File "/cluster/home/ifiddes/try2/nanopore/submodules/jobTree/scriptTree/stack.py", line 153, in execute
log.txt:	    self.target.run()
log.txt:	  File "/cluster/home/ifiddes/try2/nanopore/submodules/jobTree/scriptTree/target.py", line 197, in run
log.txt:	    func(*((self,) + tuple(self.args)), **self.kwargs)
log.txt:	  File "/cluster/home/ifiddes/try2/nanopore/nanopore/pipeline.py", line 50, in runAnalyses
log.txt:	    target.addChildTarget(analysis(readFastaFile, referenceFastaFile, samFile, analysisDir))
log.txt:	TypeError: __init__() takes exactly 1 argument (5 given)
log.txt:	Exiting the slave because of a failed job on host kolossus
log.txt:	Due to failure we are reducing the remaining retry count of job /cluster/home/ifiddes/try2/nanopore/testJobTree/jobs/t1/job to 0
log.txt:	We have set the default memory of the failed job to 2147483648 bytes
log.txt:	Experiment dir tests/output/experiment_reads.fa_reference.fa_Bwa
Got message from job at time: 1403585981.01 : Experiment dir already exists: tests/output/experiment_reads.fa_reference.fa_Bwa
Job: /cluster/home/ifiddes/try2/nanopore/testJobTree/jobs/t1/job is completely failed
Only failed jobs and their dependents (3 total) are remaining, so exiting.
Finished the main loop
Traceback (most recent call last):
  File "./nanopore/pipeline.py", line 85, in <module>
    main()
  File "/cluster/home/ifiddes/try2/nanopore/nanopore/pipeline.py", line 81, in main
    raise RuntimeError("Got failed jobs")
RuntimeError: Got failed jobs
